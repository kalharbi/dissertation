%!TEX root = main.tex
\chapter{Evaluation}
\label{ch:evaluation}

\section{Introduction}
This dissertation introduces a deep and longitudinal approach for mining mobile applications.
I use the term ``deep'' to refer to the deep and structural indexing of apps across multiple levels, and the term ``longitudinal'' to refer to observing them over time.
The expected major contribution of this dissertation research is the advancement of understanding mobile apps at deep and holistic levels.
The work proposed here aims at gaining more insights into mobile apps by enabling the analysis at unprecedented depth over time.
Specifically, this dissertation aims to answer the following research questions:
\begin{enumerate}
	\item How can we enable deep searching and mining of mobile apps over time?
	\item What are the benefits of the deep and longitudinal approach for mining mobile apps?
\end{enumerate}
%TODO: Talk about the implications of answering these two research questions on search engines and data mining applications.

In answering the first question, a novel large-scale datasets have been collected and led to the development and deployment of systems (discussed in chapter \ref{ch:mining_design_changes_chapter} and \ref{ch:sieveable_chapter}).
In this chapter, I expand on answering the second question by discussing my plan for evaluating the effectiveness of the deep and longitudinal approach.
Finally, I discuss the timeline that will be followed to complete this dissertation.

\section{Evaluation}
I have empirically demonstrated that Sieveable can enable a deep and holistic search for mobile apps for various applications (see chapter \ref{ch:findings_chapter}).
To evaluate the effectiveness of Sieveable as a search system, I propose the use of the standardly used measures for information retrieval effectiveness, precision and recall \cite{manning_2008_intro_to_IR}.
Precision refers to the fraction of retrieved results that are correct, while recall refers to the fraction of correct results that are retrieved.
The test dataset will be randomly selected and consist of sixty applications with at least two versions.
Forty search query examples will be extracted from the test dataset to act as our ground truth.
The examples will cover the levels indexed by the search engine (listing details, user interface, manifest, and code).
Correctness will be assessed manually by looking at the apps before submitting the queries into the search engine.

Furthermore, I propose applying a comprehensive and careful evaluation to verify the significance of the deep and longitudinal approach of mining mobile apps at large-scale.
Specifically, the evaluation attempts to answer the following questions:
\begin{enumerate}
	\item What could a deep view of apps mining accomplish what is currently not possible in a single-level view?
	\item What could a longitudinal view of apps mining accomplish what is currently not possible in a single-snapshot view?
\end{enumerate}

First, in order to evaluate the deep search approach, I propose to conduct a comparison with the previously applied single-view approaches (listing details view, user interface view, code view).
The comparison will walk through a scenario of applying each approach individually to perform a task and discuss how accuracy increases as we go deeper in the analysis to answer a specific information need.
Let us assume that we need to find examples of apps that use the platform-specific visual design language called material design.
Suppose that we are interested in finding apps that use lists and cards with material deign style.
I will select a time window of a month and randomly select \textit{N} apps for manual inspection.
By looking at their marketplace listing details page, we can identify a number, \textit{L}, of examples that have screenshots of the desired material design cards.
By inspecting their UI layout files, we can find a number, \textit{U}, of examples that have implemented the design.
By inspecting their bytecode, we can find a number, \textit{C}, of examples that have created the design.
As we go deeper in the analysis, both precision and recall increase significantly.

Second, I propose to provide experimental evidence that shows the advantage of applying the longitudinal view to app mining against the single-snapshot view.
Let us assume that we need to find the peak period of apps adopting the material design language.
I will use web search engines to collect N number of apps that have switched to material design and use that as the ground truth for my experiment.
The experiment will use Sieveable to find the release date of the first adopted version and compare the results with the ground truth I collected manually.

Finally, I plan to use practical benchmarks to evaluate the performance of Sieveable beyond its retrieval quality. In particular, the following quantitative measures will be used:
\begin{enumerate}
	\item How many apps does it index per hour?
	\item How fast is it on a single-level query?
	\item How fast is it on complex search queries?
\end{enumerate}
The results will be reported on the larger dataset (over 300,000) apps and will be used to tune the overall system performance and report on performance enhancement.

\section{Timeline}

\begin{table}
	\def\arraystretch{2}
	\centering
	\begin{tabular}{| l | l |}
		\hline
		Task & Date \\ \hline
		Evaluation & December 2015 - January 2016\\
		\hline
		Writing and completing dissertation & February 2016 \\
		\hline
		Defending the dissertation & March 2016 \\
		\hline
	\end{tabular}
	\caption{The timeline to complete the dissertation.}
	\label{tab:table_timeline}
\end{table}

Table~\ref{tab:table_timeline} shows the proposed time for completing this dissertation.
